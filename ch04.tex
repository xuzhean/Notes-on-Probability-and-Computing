\documentclass[main.tex]{subfiles}

\begin{document}
\minispacing

\section{Chernoff and Hoeffding Bounds}

The \tb{moment generating function} of a random variable $X$ is $M_X(t)=\E[e^{tX}]$, and we are interested in its existence and properties near zero. It captures all of the moments of $X$, 

\begin{theorem}
	Let $X$ be a random variable. Assuming that we can exchange the expectation and differentiation operands, then $M_X^{(n)}(t)=\E[X^ne^{eX}]$. Computed at $t=0$, we have $M_X^{(n)}(0)=\E[X^n]$.
\end{theorem}

\begin{theorem}
	Let $X$ and $Y$ be two random variables. If $M_X(t)=M_Y(t)$ for all $t \in (-\delta, \delta)$ for some $\delta > 0$, then $X$ and $Y$ have the same distribution.
\end{theorem}

\begin{theorem}
	If $X$ and $Y$ are independent random variables, then $M_{X+Y}(t)=M_X(t)M_Y(t)$.
\end{theorem}

Bounds derived from following approach are called \tb{Chernoff bounds}. Generally, for any $t > 0$,
\[\Pb(X\ge a)=\Pb(e^{tX}\ge e^{ta})\le\frac{\E[e^tX]}{e^{ta}} \Ra \Pb(X\ge a)\le \min_{t>0}\frac{\E[e^{tX}]}{e^{ta}}.\]
We can select an appropriate value of $t$ to obtain the best possible bounds. Similarly, for any $t < 0$,
\[\Pb(X\le a)=\Pb(e^{tX}\ge e^{ta})\le\frac{\E[e^tX]}{e^{ta}} \Ra \Pb(X\le a)\le \min_{t<0}\frac{\E[e^{tX}]}{e^{ta}}.\]

Let $X_1,\cdots,X_n$ be a sequence of independent Bernoulli trials with $\Pb(X_i=1)=p_i$. The sum $X=\sum_{i=1}^{n}X_i$ forms a \tb{Poisson binomial distribution}. Let $\mu=\E[X]=\sum_{i=1}^{n}p_i$, and we have
\[M_X(t)=\prod_{i=1}^{n}M_{X_i}(t)=\prod_{i=1}^{n}\left(1+p_i\cdot (e^t-1)\right)\le\prod_{i=1}^{n}e^{p_i\cdot(e^t-1)}=e^{(e^t-1)\cdot\mu}\]

\begin{theorem}
	Let $X$ be a Poisson binomial distribution, and $\mu=\E[X]$. Then the following Chernoff bounds hold:
	\[
		\Pb(X\ge(1+\delta)\cdot\mu)\le\left(\frac{e^\delta}{(1+\delta)^{1+\delta}}\right)^\mu,\quad \text{for } \delta > 0;\qquad
		\Pb(X\le(1-\delta)\cdot\mu)\le\left(\frac{e^{-\delta}}{(1-\delta)^{1-\delta}}\right)^\mu,\quad \text{for } \delta > 0. 
	\]
\end{theorem}

\begin{corollary}
	Let $X$ be a Poisson binomial distribution. Then, for $0<\delta<1$, 
	\[\Pb(X\ge(1+\delta)\cdot\mu)\le \exp\left(-\mu\delta^2\cdot (2\ln 2-1)\right),\qquad\Pb(X\ge(1-\delta)\cdot\mu)\le \exp\left(-\mu\delta^2\Div 2\right).\]
	The coefficient $(2\ln 2-1)$ and $1/2$ are derived from $\min((1+\delta)\cdot \ln(1+\delta)\Div\delta^2 - 1\Div \delta)$ in $\delta\in(0,1)$ and $\delta\in(-1,0)$.
\end{corollary}

\begin{theorem}
	Let $X$ be a binomial distribution where $p=1/2$. Then,
	\[
		\Pb(X\ge(1+\delta)\cdot\mu)\le \exp\left(-\delta^2\mu\right),\quad\text{for }\delta>0;\qquad
		\Pb(X\le(1-\delta)\cdot\mu)\le \exp\left(-\delta^2\mu\right),\quad\text{for }0<\delta<1.
	\]
\end{theorem}

\begin{lemma}\na{Hoeffding's lemma}
	Let $X$ be a random variable such that $\Pb(X\in[a,b])=1$. Then for every $\lambda>0$,
	\[\E[e^{\lambda X}]\le\exp\left(\lambda\mu+\frac{\lambda^2\cdot(b-a)^2}{8}\right),\qquad \text{where }\mu=\E[X].\]
\end{lemma}

\begin{pf}
	Assume $\E[X]=0$ and $a\le 0\le b$. Since $e^{\lambda x}$ is a convex function, we have
	\[\E[e^{\lambda X}]\le\E\left[\frac{b-X}{b-a}\cdot e^{\lambda a}\right] + \E\left[\frac{X-a}{b-a}\cdot e^{\lambda b}\right] = \frac{b}{b-a}\cdot e^{\lambda a} - \frac{a}{b-a}\cdot e^{\lambda b} = e^{g(u)},\quad\text{where }u=\lambda\cdot(b-a).\]
	Then $g(u)=-c\cdot u+\ln(1-c+c\cdot e^u)$ with $c=-a\,/\,(b-a)$. We can verify that $g(0)=g'(0)=0$ and $g''(u)\le 1/4$. By Taylor's theorem, for any $u > 0$ there is a $u_0\in[0,u]$ such that $g(u)=g(0)+u\cdot g(0)+u^2\cdot g''(u_0)\,/\,2\le u^2\,/\,8$.
\end{pf}

\begin{theorem}\na{Hoeffding bound}
	Let $X_1,\cdots,X_n$ be independent random variables with $\E[X_i]=\mu_i$ and $\Pb(a_i\le X\le b_i)=1$ for constants $a_i$ and $b_i$. Then
	\[
		\Pb\left(\sum_{i=1}^{n}X_i-\sum_{i=1}^{n}\mu_i\ge\eps\right)\le \exp\left(\frac{-2\cdot\eps^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\right)
	\]
\end{theorem}

\begin{pf}
	Let $Z_i=X_i-\mu_i$ and $Z=\sum_{i=1}^{n}Z_i$. For any $\lambda>0$, by Chernoff's approach, we have
	\[
		\Pb(Z\ge\eps)=\Pb\left(e^{\lambda Z}\ge e^{\lambda\eps}\right) \le \frac{\E[e^{\lambda Z}]}{e^{\lambda \eps}}=\frac{\prod_{i=1}^{n}\E[e^{\lambda Z_i}]}{e^{\lambda \eps}}\le\exp\left(-\lambda\eps+\lambda^2\cdot\sum_{i=1}^{n}\frac{(b_i-a_i)^2}{8}\right)
	\]
	Let $\lambda = 4\eps / (\sum_{i=1}^{n}(b_i-a_i)^2)$, and it follows Hoeffding bound.
\end{pf}

\bigskip

{\bs Packet routing in sparse networks} ...

\bigskip

\ex{4.9} (a) Let $Z=\sum_{i=1}^{n} X_i / n$, and we have $\Var[Z] = \sum_{i=1}^{n}\Var[X_i] / n^2 = \Var[X] / n$. By Chebyshevâ€™s Inequality, $\Pb(|X-\E[X]]\ge \eps\cdot \E[X])\le \Var[X] \Div (\sigma^2\cdot\E[X]^2) \le r^2\Div(n\cdot\sigma^2) \le \delta \Ra n \ge r^2\Div(\sigma^2\cdot\delta)$. (c) Assume that we have obtained $m=\lceil 12\log\frac{1}{\delta}\rceil$ independent estimates $S_1,\cdots,S_m$ for $\E[X]$. Let $Y_i$ be the $0$\;\!-$1$ random variable that is $1$ if and only if $|S_i-\E[X]|\ge\eps\cdot\mu$. $\E[Y_i]\le 1/4$. Applying the Chernoff bound gives $\Pb(|M-\E[X]|\ge\eps\cdot\E[X])\le\Pb(Y\ge(1+1)\cdot m \Div 4)\le\exp(-(m/4)\cdot 1^2\cdot(2\ln 2-1))\le\delta$.

\end{document}
